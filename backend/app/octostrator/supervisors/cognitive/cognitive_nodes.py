"""
Cognitive Layer Nodes - ë²”ìš© ì¸ì§€ ë ˆì´ì–´

ë„ë©”ì¸ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ë²”ìš© Intent Understanding ë° Planning ë…¸ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

âš ï¸ í˜„ì¬ ìƒíƒœ (ë²”ìš© ì‹œìŠ¤í…œ)
==========================================
ì´ ëª¨ë“ˆì˜ ë…¸ë“œë“¤ì€ ëª¨ë“  ë„ë©”ì¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤:

**Intent Understanding**:
- LLM ê¸°ë°˜ ë™ì  intent ë¶„ë¥˜
- í•˜ë“œì½”ë”©ëœ ì¹´í…Œê³ ë¦¬ ì—†ìŒ
- ë„ë©”ì¸ ë…ë¦½ì  ì²˜ë¦¬

**Planning**:
- ë™ì  agent ì„ íƒ (í–¥í›„ êµ¬í˜„)
- LLM ê¸°ë°˜ ê³„íš ìƒì„± (í–¥í›„ êµ¬í˜„)
- Multi-step plan ì§€ì› (í–¥í›„ êµ¬í˜„)

ğŸ”® ë„ë©”ì¸ë³„ ì‚¬ìš© ì˜ˆì‹œ
==========================================

## Fitness ë„ë©”ì¸
```python
state = {
    "user_query": "ì˜¤ëŠ˜ ìš´ë™ ë£¨í‹´ ì¶”ì²œí•´ì¤˜",
    "llm": llm_instance
}
result = await intent_understanding_node(state)
# Output: {
#   "user_intent": "ìš´ë™ í”„ë¡œê·¸ë¨ ì¶”ì²œ ìš”ì²­",
#   "intent_confidence": 0.92,
#   "intent_reasoning": "ì‚¬ìš©ìê°€ ì˜¤ëŠ˜ ìˆ˜í–‰í•  ìš´ë™ ë£¨í‹´ì— ëŒ€í•œ ì¶”ì²œì„ ìš”ì²­í•¨"
# }
```

## Medical ë„ë©”ì¸
```python
state = {
    "user_query": "í™˜ì ì§„ë£Œ ê¸°ë¡ ë¶„ì„í•´ì¤˜",
    "llm": llm_instance
}
result = await intent_understanding_node(state)
# Output: {
#   "user_intent": "ì˜ë£Œ ë°ì´í„° ë¶„ì„ ìš”ì²­",
#   "intent_confidence": 0.95,
#   "intent_reasoning": "í™˜ìì˜ ì§„ë£Œ ê¸°ë¡ì— ëŒ€í•œ ë¶„ì„ì„ ìš”ì²­í•¨"
# }
```

## Legal ë„ë©”ì¸
```python
state = {
    "user_query": "ê³„ì•½ì„œ ê²€í† í•´ì¤˜",
    "llm": llm_instance
}
result = await intent_understanding_node(state)
# Output: {
#   "user_intent": "ë²•ë¥  ë¬¸ì„œ ê²€í†  ìš”ì²­",
#   "intent_confidence": 0.88,
#   "intent_reasoning": "ê³„ì•½ì„œì— ëŒ€í•œ ë²•ë¥ ì  ê²€í† ë¥¼ ìš”ì²­í•¨"
# }
```

## Education ë„ë©”ì¸
```python
state = {
    "user_query": "í•™ìƒ ê³¼ì œ í‰ê°€í•´ì¤˜",
    "llm": llm_instance
}
result = await intent_understanding_node(state)
# Output: {
#   "user_intent": "êµìœ¡ ì½˜í…ì¸  í‰ê°€ ìš”ì²­",
#   "intent_confidence": 0.90,
#   "intent_reasoning": "í•™ìƒì´ ì œì¶œí•œ ê³¼ì œì— ëŒ€í•œ í‰ê°€ë¥¼ ìš”ì²­í•¨"
# }
```

ğŸ“š See Also
==========================================
- cognitive_helpers.py: LLM ê¸°ë°˜ IntentClassifier êµ¬í˜„
- planning_node: Intentë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„íš ìˆ˜ë¦½
- backend/app/octostrator/execution_agents/base/: Base Agent íŒ¨í„´

Author: Specialist Agent Development Team
Date: 2025-11-10
Version: 2.0 (Domain-Agnostic)
"""

import logging
from typing import Dict, Any, List, Literal

from langchain_core.messages import HumanMessage, AIMessage
from .cognitive_helpers import IntentClassifier

logger = logging.getLogger(__name__)


# ====================================
# COGNITIVE NODES
# ====================================

async def intent_understanding_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Intent Understanding Node - LLM ê¸°ë°˜ ë™ì  ì˜ë„ ë¶„ë¥˜

    ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ LLMì„ í†µí•´ ë™ì ìœ¼ë¡œ íŒŒì•…í•©ë‹ˆë‹¤.
    ë„ë©”ì¸ ì œì•½ ì—†ì´ ë‹¤ì–‘í•œ ì˜ë„ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    âš ï¸ í˜„ì¬ ìƒíƒœ (ë²”ìš© ì‹œìŠ¤í…œ)
    ==========================================
    - LLM ê¸°ë°˜ ë™ì  intent ë¶„ë¥˜
    - í•˜ë“œì½”ë”©ëœ ì¹´í…Œê³ ë¦¬ ì—†ìŒ
    - ëª¨ë“  ë„ë©”ì¸ ì§€ì› (Fitness, Medical, Legal, Education ë“±)

    ğŸ”® ì‘ë™ ë°©ì‹
    ==========================================

    1. **LLM ì‚¬ìš© ê°€ëŠ¥**: IntentClassifierì˜ LLM ê¸°ë°˜ ë¶„ë¥˜ ì‚¬ìš©
       - ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ LLMì— ì „ë‹¬
       - JSON í˜•ì‹ìœ¼ë¡œ intent, confidence, reasoning ë°˜í™˜
       - ë„ë©”ì¸ ë…ë¦½ì  ì²˜ë¦¬

    2. **LLM ì‚¬ìš© ë¶ˆê°€**: Fallback ë¶„ë¥˜ ì‚¬ìš©
       - ê¸°ë³¸ intent ë°˜í™˜ ("general_task")
       - ë‚®ì€ confidence (0.5)
       - ì‹œìŠ¤í…œì€ ê³„ì† ì‘ë™

    ğŸ“ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­
    ==========================================

    ## IntentClassifier í†µí•©

    ```python
    from .cognitive_helpers import IntentClassifier

    classifier = IntentClassifier()
    intent_result = await classifier.classify(user_query, llm)
    ```

    ## State ìš”êµ¬ì‚¬í•­

    **í•„ìˆ˜**:
    - `user_query` (str): ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬

    **ì„ íƒì **:
    - `llm`: LangChain LLM ì¸ìŠ¤í„´ìŠ¤ (ì—†ìœ¼ë©´ fallback ì‚¬ìš©)
    - `messages` (list): ëŒ€í™” íˆìŠ¤í† ë¦¬ (í˜„ì¬ ë¯¸ì‚¬ìš©, í–¥í›„ context í™œìš© ê°€ëŠ¥)

    ## Return Value

    ```python
    {
        "user_intent": str,           # ë¶„ë¥˜ëœ ì˜ë„ (ì˜ˆ: "ìš´ë™ í”„ë¡œê·¸ë¨ ì¶”ì²œ ìš”ì²­")
        "intent_confidence": float,   # ì‹ ë¢°ë„ (0.0-1.0)
        "intent_reasoning": str       # LLMì˜ íŒë‹¨ ì´ìœ  (LLM ì‚¬ìš© ì‹œ)
    }
    ```

    ğŸ“š ë„ë©”ì¸ë³„ ì‚¬ìš© ì˜ˆì‹œ
    ==========================================

    ## Fitness ë„ë©”ì¸
    ```python
    state = {
        "user_query": "ì˜¤ëŠ˜ ìš´ë™ ë£¨í‹´ ì¶”ì²œí•´ì¤˜",
        "llm": llm_instance
    }

    result = await intent_understanding_node(state)
    # Output: {
    #   "user_intent": "ìš´ë™ í”„ë¡œê·¸ë¨ ì¶”ì²œ ìš”ì²­",
    #   "intent_confidence": 0.92,
    #   "intent_reasoning": "ì‚¬ìš©ìê°€ ì˜¤ëŠ˜ ìˆ˜í–‰í•  ìš´ë™ ë£¨í‹´ì— ëŒ€í•œ ì¶”ì²œì„ ìš”ì²­í•¨"
    # }
    ```

    ## Medical ë„ë©”ì¸
    ```python
    state = {
        "user_query": "í™˜ì ì§„ë£Œ ê¸°ë¡ ë¶„ì„í•´ì¤˜",
        "llm": llm_instance
    }

    result = await intent_understanding_node(state)
    # Output: {
    #   "user_intent": "ì˜ë£Œ ë°ì´í„° ë¶„ì„ ìš”ì²­",
    #   "intent_confidence": 0.95,
    #   "intent_reasoning": "í™˜ìì˜ ì§„ë£Œ ê¸°ë¡ì— ëŒ€í•œ ë¶„ì„ì„ ìš”ì²­í•¨"
    # }
    ```

    ## Legal ë„ë©”ì¸
    ```python
    state = {
        "user_query": "ê³„ì•½ì„œ ê²€í† í•´ì¤˜",
        "llm": llm_instance
    }

    result = await intent_understanding_node(state)
    # Output: {
    #   "user_intent": "ë²•ë¥  ë¬¸ì„œ ê²€í†  ìš”ì²­",
    #   "intent_confidence": 0.88,
    #   "intent_reasoning": "ê³„ì•½ì„œì— ëŒ€í•œ ë²•ë¥ ì  ê²€í† ë¥¼ ìš”ì²­í•¨"
    # }
    ```

    ## Education ë„ë©”ì¸
    ```python
    state = {
        "user_query": "í•™ìƒ ê³¼ì œ í‰ê°€í•´ì¤˜",
        "llm": llm_instance
    }

    result = await intent_understanding_node(state)
    # Output: {
    #   "user_intent": "êµìœ¡ ì½˜í…ì¸  í‰ê°€ ìš”ì²­",
    #   "intent_confidence": 0.90,
    #   "intent_reasoning": "í•™ìƒì´ ì œì¶œí•œ ê³¼ì œì— ëŒ€í•œ í‰ê°€ë¥¼ ìš”ì²­í•¨"
    # }
    ```

    ## Fallback (LLM ì—†ì„ ë•Œ)
    ```python
    state = {
        "user_query": "ë„ì™€ì¤˜",
        # llm ì—†ìŒ
    }

    result = await intent_understanding_node(state)
    # Output: {
    #   "user_intent": "general_task",
    #   "intent_confidence": 0.5,
    #   "intent_reasoning": "LLM unavailable, using fallback classification"
    # }
    ```

    ğŸ”„ í–¥í›„ í™•ì¥ ê°€ëŠ¥ì„±
    ==========================================

    ### Option A: Registry ê¸°ë°˜ ë¶„ë¥˜ ì¶”ê°€

    Agent Registryì˜ capabilitiesë¥¼ í™œìš©í•˜ì—¬ ë¶„ë¥˜:

    ```python
    from backend.app.octostrator.execution_agents import agent_registry

    # Registry ê¸°ë°˜ ë¶„ë¥˜ê¸° ì‚¬ìš©
    classifier = IntentClassifier(registry=agent_registry)
    intent_result = await classifier.classify_with_registry(user_query)
    ```

    ### Option B: Conversation Context í™œìš©

    ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í™œìš©í•œ context-aware ë¶„ë¥˜:

    ```python
    messages = state.get("messages", [])

    # Contextë¥¼ í¬í•¨í•œ ë¶„ë¥˜
    intent_result = await classifier.classify_with_context(
        user_query,
        llm,
        context=messages
    )
    ```

    ### Option C: Multi-Intent ì§€ì›

    í•˜ë‚˜ì˜ ì¿¼ë¦¬ì—ì„œ ì—¬ëŸ¬ ì˜ë„ ê°ì§€:

    ```python
    # "í™˜ì ì§„ë£Œ ê¸°ë¡ ë¶„ì„í•˜ê³  ë³´ê³ ì„œ ìƒì„±í•´ì¤˜"
    intent_result = await classifier.classify_multi_intent(user_query, llm)
    # Output: {
    #   "intents": [
    #       {"intent": "ì˜ë£Œ ë°ì´í„° ë¶„ì„", "confidence": 0.95},
    #       {"intent": "ë³´ê³ ì„œ ìƒì„±", "confidence": 0.92}
    #   ]
    # }
    ```

    âš ï¸ Error Handling
    ==========================================

    - **LLM ì—†ìŒ**: Fallbackìœ¼ë¡œ "general_task" ë°˜í™˜ (confidence 0.5)
    - **LLM ì˜¤ë¥˜**: Exception ë°œìƒ ì‹œ fallbackìœ¼ë¡œ ì²˜ë¦¬
    - **JSON íŒŒì‹± ì˜¤ë¥˜**: IntentClassifier ë‚´ë¶€ì—ì„œ ì²˜ë¦¬
    - **ë¹ˆ ì¿¼ë¦¬**: ë¹ˆ ë¬¸ìì—´ë„ ì •ìƒ ì²˜ë¦¬ (LLMì´ íŒë‹¨)

    ğŸ“Œ See Also
    ==========================================
    - cognitive_helpers.py: IntentClassifier êµ¬í˜„ (LLM ê¸°ë°˜ ë¶„ë¥˜ ë¡œì§)
    - planning_node: Intentë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
    - backend/app/octostrator/execution_agents/base/: Base Agent íŒ¨í„´

    Args:
        state: LangGraph state dictionary
            - user_query (str): ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬ (í•„ìˆ˜)
            - llm: LangChain LLM ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒì )
            - messages (list): ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒì )

    Returns:
        dict: Intent ë¶„ë¥˜ ê²°ê³¼
            - user_intent (str): ë¶„ë¥˜ëœ ì˜ë„
            - intent_confidence (float): ì‹ ë¢°ë„ (0.0-1.0)
            - intent_reasoning (str): LLMì˜ íŒë‹¨ ì´ìœ 

    Raises:
        Exception: ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ ì‹œ (ë¡œê¹… í›„ error í‚¤ ë°˜í™˜)
    """
    try:
        user_query = state.get("user_query", "")
        messages = state.get("messages", [])

        # Contextì—ì„œ LLM ê°€ì ¸ì˜¤ê¸°
        llm = state.get("llm")  # LLMì´ ì—†ìœ¼ë©´ fallback ì‚¬ìš©

        logger.info(f"[Intent] Analyzing: {user_query[:50]}...")

        # LLM ê¸°ë°˜ IntentClassifier ì‚¬ìš©
        classifier = IntentClassifier()
        intent_result = await classifier.classify(user_query, llm)

        logger.info(
            f"[Intent] Classified: '{intent_result['intent']}' "
            f"(confidence: {intent_result['confidence']:.2f})"
        )

        return {
            "user_intent": intent_result["intent"],
            "intent_confidence": intent_result["confidence"],
            "intent_reasoning": intent_result.get("reasoning", "")
        }

    except Exception as e:
        logger.error(f"[Intent] Error: {e}")
        return {"error": str(e)}


async def planning_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Planning Node - LLM ê¸°ë°˜ ë™ì  ê³„íš ìˆ˜ë¦½

    ì‚¬ìš©ì ì˜ë„ì™€ ì‚¬ìš© ê°€ëŠ¥í•œ Agentë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰ ê³„íšì„ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

    âš ï¸ í˜„ì¬ ìƒíƒœ (ë²”ìš© ì‹œìŠ¤í…œ)
    ==========================================
    - LLM ê¸°ë°˜ ë™ì  ê³„íš ìˆ˜ë¦½
    - í•˜ë“œì½”ë”©ëœ agent ì—†ìŒ (ì´ì „ì˜ "diet_agent" ì œê±°ë¨)
    - ëª¨ë“  ë„ë©”ì¸ ì§€ì› (Fitness, Medical, Legal, Education ë“±)

    ğŸ”® ì‘ë™ ë°©ì‹
    ==========================================

    **í˜„ì¬ êµ¬í˜„** (Simple Fallback):
    1. LLMì´ ì—†ê±°ë‚˜ Agent Registryê°€ ì—†ëŠ” ê²½ìš°
    2. ê¸°ë³¸ ê³„íš ë°˜í™˜ (ë‹¨ì¼ step, general_agent)
    3. ì‹œìŠ¤í…œì€ ê³„ì† ì‘ë™

    **í–¥í›„ êµ¬í˜„** (LLM ê¸°ë°˜ ë™ì  ê³„íš):
    1. LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„
    2. ì‚¬ìš© ê°€ëŠ¥í•œ Agent ëª©ë¡ ì¡°íšŒ (Agent Registry)
    3. LLMì´ ì í•©í•œ Agent ì„ íƒ ë° ê³„íš ìƒì„±
    4. Multi-step ê³„íš ì§€ì› (ë³µì¡í•œ ì‘ì—… ë¶„í•´)

    ğŸ“ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­
    ==========================================

    ## State ìš”êµ¬ì‚¬í•­

    **í•„ìˆ˜**:
    - `user_query` (str): ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬
    - `user_intent` (str): Intent Understandingì—ì„œ ë¶„ë¥˜ëœ ì˜ë„

    **ì„ íƒì **:
    - `llm`: LangChain LLM ì¸ìŠ¤í„´ìŠ¤ (í–¥í›„ êµ¬í˜„ì—ì„œ ì‚¬ìš©)

    ## Return Value

    ```python
    {
        "plan": {
            "goal": str,              # ì‚¬ìš©ìì˜ ëª©í‘œ
            "intent": str,            # ë¶„ë¥˜ëœ ì˜ë„
            "steps": [                # ì‹¤í–‰ ë‹¨ê³„ ëª©ë¡
                {
                    "step_id": str,   # ë‹¨ê³„ ID (step_1, step_2, ...)
                    "agent": str,     # ì‹¤í–‰í•  Agent ID
                    "action": str,    # Agentê°€ ìˆ˜í–‰í•  ì‘ì—…
                    "params": dict,   # ì¶”ê°€ íŒŒë¼ë¯¸í„°
                    "dependencies": list  # ì˜ì¡´í•˜ëŠ” ì´ì „ ë‹¨ê³„ ID
                }
            ]
        },
        "is_planning": bool           # ê³„íš ìˆ˜ë¦½ ì™„ë£Œ ì—¬ë¶€
    }
    ```

    ğŸ“š ë„ë©”ì¸ë³„ ì‚¬ìš© ì˜ˆì‹œ (í–¥í›„ LLM ê¸°ë°˜ êµ¬í˜„)
    ==========================================

    ## Fitness ë„ë©”ì¸
    ```python
    state = {
        "user_intent": "ìš´ë™ í”„ë¡œê·¸ë¨ ì¶”ì²œ ìš”ì²­",
        "user_query": "ì˜¤ëŠ˜ ìš´ë™ ë£¨í‹´ ì¶”ì²œí•´ì¤˜",
        "llm": llm_instance
    }

    result = await planning_node(state)
    # í–¥í›„ Output (LLM ê¸°ë°˜):
    # {
    #   "plan": {
    #       "goal": "ì˜¤ëŠ˜ ìš´ë™ ë£¨í‹´ ì¶”ì²œí•´ì¤˜",
    #       "intent": "ìš´ë™ í”„ë¡œê·¸ë¨ ì¶”ì²œ ìš”ì²­",
    #       "steps": [
    #           {
    #               "step_id": "step_1",
    #               "agent": "fitness_program_agent",
    #               "action": "recommend_workout_routine",
    #               "params": {"timeframe": "today"},
    #               "dependencies": []
    #           }
    #       ]
    #   },
    #   "is_planning": False
    # }
    ```

    ## Medical ë„ë©”ì¸
    ```python
    state = {
        "user_intent": "ì˜ë£Œ ë°ì´í„° ë¶„ì„ ìš”ì²­",
        "user_query": "í™˜ì ì§„ë£Œ ê¸°ë¡ ë¶„ì„í•´ì¤˜",
        "llm": llm_instance
    }

    result = await planning_node(state)
    # í–¥í›„ Output (Multi-step):
    # {
    #   "plan": {
    #       "goal": "í™˜ì ì§„ë£Œ ê¸°ë¡ ë¶„ì„í•´ì¤˜",
    #       "steps": [
    #           {
    #               "step_id": "step_1",
    #               "agent": "medical_data_agent",
    #               "action": "analyze_medical_records",
    #               "params": {"data_type": "ì§„ë£Œê¸°ë¡"},
    #               "dependencies": []
    #           },
    #           {
    #               "step_id": "step_2",
    #               "agent": "report_generator_agent",
    #               "action": "generate_summary",
    #               "params": {},
    #               "dependencies": ["step_1"]
    #           }
    #       ]
    #   },
    #   "is_planning": False
    # }
    ```

    ## Legal ë„ë©”ì¸
    ```python
    state = {
        "user_intent": "ë²•ë¥  ë¬¸ì„œ ê²€í†  ìš”ì²­",
        "user_query": "ê³„ì•½ì„œ ê²€í† í•´ì¤˜",
        "llm": llm_instance
    }

    result = await planning_node(state)
    # í–¥í›„ Output:
    # {
    #   "plan": {
    #       "goal": "ê³„ì•½ì„œ ê²€í† í•´ì¤˜",
    #       "steps": [
    #           {
    #               "step_id": "step_1",
    #               "agent": "legal_document_agent",
    #               "action": "review_contract",
    #               "params": {"query": "ê³„ì•½ì„œ ê²€í† í•´ì¤˜"},
    #               "dependencies": []
    #           }
    #       ]
    #   },
    #   "is_planning": False
    # }
    ```

    ## Education ë„ë©”ì¸
    ```python
    state = {
        "user_intent": "êµìœ¡ ì½˜í…ì¸  í‰ê°€ ìš”ì²­",
        "user_query": "í•™ìƒ ê³¼ì œ í‰ê°€í•´ì¤˜",
        "llm": llm_instance
    }

    result = await planning_node(state)
    # í–¥í›„ Output:
    # {
    #   "plan": {
    #       "goal": "í•™ìƒ ê³¼ì œ í‰ê°€í•´ì¤˜",
    #       "steps": [
    #           {
    #               "step_id": "step_1",
    #               "agent": "education_assessment_agent",
    #               "action": "evaluate_assignment",
    #               "params": {},
    #               "dependencies": []
    #           }
    #       ]
    #   },
    #   "is_planning": False
    # }
    ```

    ğŸ”„ í–¥í›„ êµ¬í˜„ ì˜µì…˜
    ==========================================

    ### Option A: LLM ê¸°ë°˜ ë™ì  ê³„íš ìƒì„±

    ```python
    import json
    from langchain_core.messages import HumanMessage

    async def planning_node(state: Dict[str, Any]) -> Dict[str, Any]:
        llm = state.get("llm")
        user_intent = state.get("user_intent", "")
        user_query = state.get("user_query", "")

        # Agent Registryì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ Agent ì¡°íšŒ
        # available_agents = agent_registry.list_agents()
        # agents_info = [...]

        prompt = f\"\"\"Create an execution plan.

User Intent: {user_intent}
User Query: {user_query}

Available Agents: [agent1, agent2, ...]

Return JSON with goal, intent, and steps.\"\"\"

        response = await llm.ainvoke([HumanMessage(content=prompt)])
        plan = json.loads(response.content)

        return {"plan": plan, "is_planning": False}
    ```

    ### Option B: Capability ê¸°ë°˜ Agent ì„ íƒ

    ```python
    from backend.app.octostrator.execution_agents.base.capabilities import CapabilityBasedRouter

    async def planning_node(state: Dict[str, Any]) -> Dict[str, Any]:
        router = CapabilityBasedRouter(agent_registry)

        # Intentë¥¼ Capabilityë¡œ ë³€í™˜
        required_capability = intent_to_capability(state.get("user_intent"))

        # Capabilityì— ë§ëŠ” Agent ì„ íƒ
        selected_agent = router.find_best_agent(required_capability)

        plan = {
            "goal": state.get("user_query"),
            "steps": [{
                "step_id": "step_1",
                "agent": selected_agent,
                "action": "analyze_and_execute",
                "params": {},
                "dependencies": []
            }]
        }

        return {"plan": plan, "is_planning": False}
    ```

    ### Option C: í˜¼í•© ë°©ì‹ (LLM + Capability)

    ë³µì¡í•œ ì‘ì—…ì€ LLMìœ¼ë¡œ ë¶„í•´í•˜ê³ , ê° ë‹¨ê³„ë§ˆë‹¤ Capability ê¸°ë°˜ìœ¼ë¡œ Agent ì„ íƒ.

    âš ï¸ í˜„ì¬ êµ¬í˜„ (Fallback)
    ==========================================

    í˜„ì¬ëŠ” ë‹¨ìˆœí•œ fallback ê³„íšì„ ë°˜í™˜í•©ë‹ˆë‹¤:
    - Agent: "general_agent" (ê¸°ë³¸ê°’)
    - Action: "analyze_and_execute"
    - Single-step plan

    í–¥í›„ LLM ê¸°ë°˜ ë˜ëŠ” Capability ê¸°ë°˜ êµ¬í˜„ìœ¼ë¡œ êµì²´ë  ì˜ˆì •ì…ë‹ˆë‹¤.

    ğŸ“Œ See Also
    ==========================================
    - intent_understanding_node: Intent ë¶„ë¥˜ ê²°ê³¼ í™œìš©
    - validator_node: ìƒì„±ëœ ê³„íš ê²€ì¦ (í–¥í›„ êµ¬í˜„)
    - backend/app/octostrator/execution_agents/: Agent êµ¬í˜„

    Args:
        state: LangGraph state dictionary
            - user_intent (str): ë¶„ë¥˜ëœ ì˜ë„ (í•„ìˆ˜)
            - user_query (str): ì‚¬ìš©ì ì¿¼ë¦¬ (í•„ìˆ˜)
            - llm: LLM ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒì , í–¥í›„ ì‚¬ìš©)

    Returns:
        dict: ì‹¤í–‰ ê³„íš
            - plan (dict): ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš
            - is_planning (bool): ê³„íš ìˆ˜ë¦½ ì™„ë£Œ (í•­ìƒ False)

    Raises:
        Exception: ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ ì‹œ (ë¡œê¹… í›„ error í‚¤ ë°˜í™˜)
    """
    try:
        user_intent = state.get("user_intent", "")
        user_query = state.get("user_query", "")

        # í˜„ì¬ëŠ” ê°„ë‹¨í•œ fallback plan ìƒì„±
        # í–¥í›„ LLM ê¸°ë°˜ ë™ì  ê³„íš ìƒì„±ìœ¼ë¡œ êµì²´ ì˜ˆì •
        # TODO: Implement LLM-based planning with Agent Registry

        plan = {
            "goal": user_query,
            "intent": user_intent,
            "steps": [
                {
                    "step_id": "step_1",
                    "agent": "general_agent",  # ë²”ìš© agent (í•˜ë“œì½”ë”©ëœ "diet_agent" ì œê±°ë¨)
                    "action": "analyze_and_execute",
                    "params": {"query": user_query},
                    "dependencies": []
                }
            ]
        }

        logger.info(f"[Planning] Generated plan with {len(plan['steps'])} step(s)")

        return {
            "plan": plan,
            "is_planning": False
        }

    except Exception as e:
        logger.error(f"[Planning] Error: {e}")
        return {"error": str(e)}


async def validator_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Validator Node

    ìƒì„±ëœ ê³„íšì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.

    Checks:
    - Agent availability
    - Dependency cycles
    - Resource constraints
    """
    try:
        plan = state.get("plan", {})

        # TODO: Implement validation logic
        # For now, always valid

        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": []
        }

        logger.info(f"[Validator] Plan validation: {validation_result['valid']}")

        return {
            "validation_result": validation_result,
            "plan_valid": validation_result["valid"]
        }

    except Exception as e:
        logger.error(f"[Validator] Error: {e}")
        return {"error": str(e)}